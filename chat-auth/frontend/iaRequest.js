async function getOllamaResponse(message, model = 'deepseek-r1:8b') {
    const fetch = (await import('node-fetch')).default;

    try {
        const response = await fetch('http://localhost:11434/api/generate', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ model, prompt: message, stream: false }) 
        });

        const rawData = await response.text();

        const data = JSON.parse(rawData);

        if (!data.done || !data.response) {
            throw new Error("Aucune r√©ponse valide d'Ollama.");
        }

        let responseText = data.response
        console.log("R√©ponse brute d'Ollama:", responseText);
        const thinkingPhaseMatch = responseText.match(/<think>(.*?)<\/think>/s);
        console.log("ThinkingPhaseMatch:", thinkingPhaseMatch);
        const responseMarkdown = responseText.replace(/<think>.*?<\/think>/s, '').trim();
        console.log("R√©ponse Markdown:", responseMarkdown);

        let thinkingPhase = '*(Phase de r√©flexion indisponible...)*';

        if (thinkingPhaseMatch[0] == "<think>\n\n</think>") {
            thinkingPhase = '*Pas de phase de r√©flexion...*';
        } else {   
            if (thinkingPhaseMatch) {
                thinkingPhase = thinkingPhaseMatch[1].trim();
                // thinkingPhase = thinkingPhase.replace(/^(.*)$/gm, '*$1*');
            } else {
                thinkingPhase = '*(Phase de r√©flexion non trouv√©e...)*';
            }
        }   

        return `
#### üß† Phase de r√©flexion :
> ${thinkingPhase}\n

---

### üêí R√©ponse :
${responseMarkdown}
        `;

    } catch (err) {
        console.error('Erreur avec Ollama:', err);
        return "D√©sol√©, je ne peux pas r√©pondre pour l'instant.";
    }
}

module.exports = { getOllamaResponse };